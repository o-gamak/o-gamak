# Data Science Projects (Yandex Practicum)

## Описание
Репозиторий содержит проекты, выполненные в рамках обучения на курсе Data Science от Yandex Practicum. Проекты демонстрируют навыки анализа данных, машинного обучения и визуализации, примененные к реальным бизнес-задачам. Каждый проект включает предобработку данных, исследовательский анализ, построение моделей и бизнес-рекомендации.

## Проекты

1. **Исследовательский анализ (Недвижимость)**
   - **Что делалось:** Анализ объявлений о продаже квартир в Санкт-Петербурге для сервиса "Яндекс Недвижимость". Выявление факторов, влияющих на цену, и определение аномалий для предотвращения мошенничества.
   - **Инструменты:** Python, Pandas, Matplotlib.
   - **Результаты:** 
     - Средняя цена квартиры составила 5 млн рублей, медианная — 4.2 млн рублей.
     - Ключевые факторы цены: общая площадь (корреляция 0.7), расстояние до центра (корреляция 0.6), количество комнат (0.4).
     - Выявлено 5% аномалий (цены >15 млн рублей при площади <50 м²), что может указывать на возможное мошенничество.
     - Построены графики распределения цен и тепловые карты корреляции.

2. **Сборный проект 1 (Рынок кинопроката)**
   - **Что делалось:** Анализ рынка российского кинопроката для Министерства культуры РФ. Изучение трендов, оценка эффективности фильмов с государственной поддержкой и их интереса для зрителей.
   - **Инструменты:** Python, Pandas, Matplotlib, Plotly.
   - **Результаты:** 
     - Объединено более 100 тысяч записей из данных о прокатных удостоверениях и рейтингах КиноПоиска.
     - Фильмы с государственной поддержкой составляют 10% рынка, но собирают в среднем 20 млн рублей против 40 млн у коммерческих фильмов (снижение на 50%).
     - Популярные жанры: комедии и драмы с рейтингом >6.0; поддержанные фильмы редко превышают 7.0.
     - Построены диаграммы по сборам и рейтингу, выявлены сезонные тренды (рост в новогодний период).

3. **Статистический анализ данных (GoFast)**
   - **Что делалось:** Анализ данных сервиса аренды самокатов GoFast. Проверка гипотез о поведении пользователей с подпиской (ultra) и без (free) для повышения выручки.
   - **Инструменты:** Python, Pandas, SciSci, Matplotlib, Plotly.
   - **Результаты:** 
     - Предобработка: удалено 5% дубликатов, обработаны аномалии (поездки <100 м).
     - Среднее расстояние ultra-пользователей — 3.1 км против 2.5 км у free, время поездок на 20% длиннее.
     - Гипотеза подтверждена: пользователи ultra приносят на 15% больше выручки (p-value < 0.05).
     - Рекомендовано использовать минимум 1172 промокода для снижения риска до 5%, визуализированы распределения по городам и возрасту.

4. **Линейные задачи в ML (Ферма Вольный луг)**
   - **Что делалось:** Разработка моделей для фермы "Вольный луг" для прогноза удоя коров (≥6000 кг/год) и вероятности получения вкусного молока.
   - **Инструменты:** Python, Pandas, Scikit-learn, Phik, Matplotlib, Plotly.
   - **Результаты:** 
     - Предобработка: устранены 3% пропусков, корреляция ЭКЕ и СПО с удоем составила 0.72 и 0.66 соответственно.
     - Модель удоя: R² = 0.79, RMSE = 500 кг; модель вкуса: Precision = 1.0 при пороге 0.8, Recall = 0.75.
     - Прогноз для 20 коров: медианный удой 6534 кг, только 2 коровы с вероятностью вкусного молока >80%.
     - Построены графики зависимости удоя от ЭКЕ и тепловые карты корреляции.

5. **Обучение с учителем (В один клик)**
   - **Что делалось:** Сегментация клиентов интернет-магазина "В один клик" для персонализированных предложений и повышения покупательской активности.
   - **Инструменты:** Python, Pandas, Scikit-learn, Matplotlib, Plotly.
   - **Результаты:** 
     - Предобработка: закодированы 15 категориальных признаков, обработано 10% пропусков.
     - Модель классификации: точность 85%, F1-score 0.82, выделено 10% клиентов с риском снижения активности (покупки упали на 20% за месяц).
     - Сегменты: 30% клиентов с "прежним уровнем" активности, 60% с "снижением".
     - Визуализированы распределения покупок и сегменты на дашборде.

6. **Сборный проект-2 (Работа с заботой)**
   - **Что делалось:** Предсказание уровня удовлетворенности и вероятности оттока сотрудников для компании "Работа с заботой".
   - **Инструменты:** Python, Pandas, Scikit-learn, Matplotlib, Seaborn.
   - **Результаты:** 
     - Предобработка: заполнено 8% пропусков, удалено 2% аномалий (удовлетворенность <0 или >1).
     - EDA: корреляция удовлетворенности с оттоком ~0.6, ключевой фактор — стаж <1 года (20% оттока).
     - Модель оттока: точность 80%, ROC-AUC 0.85; удовлетворенности: R² = 0.7, MAE = 0.1.
     - Рекомендация: тренинги для сотрудников с рейтингом <0.5, снижение оттока на 10-15%.

7. **Машинное обучение в бизнесе (Нефтяные скважины)**
   - **Что делалось:** Выбор оптимального региона для бурения нефтяной скважины для компании "ГлавРосГосНефть" с прибылью 518 млн руб. и риском <2.5%.
   - **Инструменты:** Python, Pandas, Scikit-learn, Bootstrap.
   - **Результаты:** 
     - Предобработка: нормализация данных, RMSE модели линейной регрессии <41 тыс. баррелей.
     - Анализ 3 регионов: регион 1 — средний запас 92 тыс. баррелей, регион 2 — 95 тыс., регион 3 — 88 тыс.
     - Bootstrap (1000 выборок): регион 2 показал нулевой риск убытков, прибыль 518 млн руб. при бюджете 10 млрд руб. и доходе 450 тыс. руб./1000 баррелей.
     - Построены графики распределения запасов и доверительные интервалы.

8. **Система обработки больших данных (Предсказание стоимости жилья в Калифорнии, PySpark)**  
   - **Что делалось:** Обучение модели линейной регрессии на больших данных о недвижимости Калифорнии 1990 года с использованием Apache Spark (PySpark MLlib). Задача — предсказание медианной стоимости дома в жилом массиве.  
   - **Инструменты:** PySpark (Spark SQL + MLlib), Pipeline, VectorAssembler, StringIndexer → OneHotEncoder, Imputer, StandardScaler, LinearRegression, RegressionEvaluator, CrossValidator.  
   - **Результаты:**  
     - Данные успешно загружены и обработаны в распределённой среде Spark.  
     - Обработаны пропуски в `total_bedrooms` (медиана), закодирован категориальный признак `ocean_proximity`.  
     - Реализован полный ML-пайплайн: предобработка → масштабирование → обучение.  
     - Финальная модель линейной регрессии показала:  
       - **RMSE = 68 421** (цель ≤ 70 000 достигнута)  
       - **MAE = 49 875**  
       - **R² = 0.651**  
     - Наиболее значимые признаки: `median_income`, `ocean_proximity_<1H OCEAN>`, `INLAND` (отрицательно), координаты.  
     - Построены корреляционная матрица и графики важности признаков.  

   **Вывод:** Модель успешно работает в распределённой среде и готова к масштабированию на миллионы строк.  

9. **Численные методы и градиентный бустинг (Не бит, не крашен — определение стоимости автомобилей)**  
   - **Что делалось:** Построение модели для быстрой и точной оценки рыночной стоимости автомобилей с пробегом в мобильном приложении сервиса «Не бит, не крашен». Критично: качество (RMSE < 2500), скорость предсказания и время обучения.  
   - **Инструменты:** Pandas, Scikit-learn, LightGBM, XGBoost, CatBoostRegressor, Pipeline, OrdinalEncoder, GridSearchCV, измерение времени.  
   - **Результаты:**  
     - Глубокая предобработка: удалены дубликаты, аномалии (цена <500 €, мощность 0/>400 л.с., год вне 1970–2024), неинформативные столбцы.  
     - Очищены и унифицированы категориальные признаки, добавлена категория `unknown` для `Repaired`.  
     - Сравнено 4 модели: RandomForest, LightGBM, XGBoost, CatBoost.  
     - **Победитель — CatBoostRegressor**:  
       - RMSE на кросс-валидации: **1570.7**  
       - RMSE на тестовой выборке: **1540.8** (в 1.6 раза лучше требования)  
       - Время обучения: 36 сек  
       - Время предсказания: **0.4 сек** (в 4 раза быстрее конкурентов)  
     - Топ-5 признаков по важности: RegistrationYear, Power, Kilometer, Brand, Model.  

   **Рекомендация:** внедрять CatBoost в продакшн — лучший баланс качества и скорости. Переобучать раз в 3–6 месяцев.

10. **Прогнозирование покупки в ближайшие 90 дней (Маркетинг интернет-магазина одежды)**
   - **Что делалось:** Построение модели бинарной классификации для предсказания вероятности покупки клиента в течение 90 дней на основе истории покупок и реакции на email/push-рассылки. Цель — оптимизация маркетинговых кампаний и повышение конверсии.
   - **Инструменты:** Python, Pandas, CatBoost/XGBoost/LightGBM, SHAP, scikit-learn, gdown, phik, seaborn.
   - **Результаты:**
     - Сгенерировано более 40 осмысленных признаков (RFM-метрики, CTR за 30/60/90 дней, recency, open_rate, days_since_last_interaction, категорийные предпочтения).
     - Проведено сравнение трёх градиентных бустингов + бейзлайн.
     - **Лучшая модель — CatBoostClassifier**:
       - **ROC-AUC на кросс-валидации: 0.8147**
       - **ROC-AUC на отложенной тестовой выборке: 0.8275** (прирост к бейзлайну +327 пунктов)
       - XGBoost отстал всего на 0.001, но обучается в 10 раз быстрее.
     - Полный SHAP-анализ:
       - Главный драйвер покупки — **ctr_30d** (чем выше кликабельность за последние 30 дней — тем горячее клиент)
       - Лояльные «старожилы» (большой промежуток между первой и последней покупкой) — наиболее склонны к покупке
       - Высокий средний чек — негативный сигнал на 90 дней («киты» покупают редко, но дорого)
       - Высокая открываемость писем без кликов — признак холодной аудитории
     - Ожидаемый бизнес-эффект:
       - Увеличение конверсии рассылок в **3–5 раз** при отправке только топ-20% по скорингу
       - Снижение спама и оттока за счёт точечной коммуникации
       - Рост выручки за счёт своевременных триггерных кампаний
     - Проект полностью воспроизводим: данные автоматически загружаются с Google Drive через `gdown`, подготовлен `requirements.txt`.
   **Вывод:** Готовый аналитический продукт с максимальной интерпретируемостью и бизнес-ценностью — готов к пилотному запуску и внедрению в CRM/маркетинговые платформы.
   
## Автор
Илья Гамаюнов, студент Yandex Practicum (Data Science).

## Как использовать
- Исходный код и отчеты доступны в соответствующих папках.
- Рекомендуется использовать Jupyter Notebook для интерактивного просмотра .ipynb файлов.
